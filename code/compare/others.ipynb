{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import precision_score, f1_score, roc_auc_score, cohen_kappa_score, confusion_matrix \n",
    "from spot import *\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcess:\n",
    "    INVALID_ITEM = -1\n",
    "    def __init__(self, data_file, data_size, config):\n",
    "        self.file = data_file\n",
    "        self.data_size = data_size\n",
    "        self.fake_eps = config['fake_eps']\n",
    "        self.min_delay = config['min_delay']\n",
    "        self.max_delay = config['max_delay']\n",
    "        self.max_bw = np.log(config['max_bw']*1024*1024)\n",
    "        self.cong_rate = config['cong_rate']\n",
    "        self.stat_size = config['stat_size']\n",
    "        self.avg_weight = config['avg_weight']\n",
    "        self.link_delay_map = {}\n",
    "        self.path_delay_map = {}\n",
    "        self.link_loads_map = {}\n",
    "        self.valid_delay_map = {}\n",
    "        self.valid_loads_map = {}\n",
    "        self.delay_limit_map = {}\n",
    "        self.quality_map = {}\n",
    "        self.dataset = []\n",
    "        self.target_dpids = self._get_target_dpids()\n",
    "    \n",
    "    def preprocess(self):\n",
    "        with open(self.file, 'r+') as fp:\n",
    "            for _ in range(self.data_size):\n",
    "                line = fp.readline()\n",
    "                if not line:\n",
    "                    break \n",
    "                self._get_link_delay(line)\n",
    "                self._get_data_item(line)\n",
    "                self._get_link_quality(line)\n",
    "    \n",
    "    def _get_target_dpids(self):\n",
    "        target_dpids = set()\n",
    "        for ep in self.fake_eps:\n",
    "            dpid = ep[0]\n",
    "            target_dpids.add(dpid)\n",
    "        return target_dpids\n",
    "    \n",
    "    def _get_link_delay(self, line):\n",
    "        res_list = line.split()\n",
    "        link = ''.join(res_list[:3])\n",
    "        loads = float(res_list[-1])\n",
    "        path_delay = float(res_list[-2])\n",
    "        cs_delay = float(res_list[-3])\n",
    "        sc_delay = float(res_list[-4])\n",
    "        link_delay = path_delay - (cs_delay + sc_delay)/2\n",
    "        if link_delay < self.min_delay:\n",
    "            link_delay = self.min_delay\n",
    "        link_delays = self.link_delay_map.setdefault(link, [])\n",
    "        link_delays.append(link_delay)\n",
    "        link_loads = self.link_loads_map.setdefault(link, [])\n",
    "        link_loads.append(loads)\n",
    "        path_delays = self.path_delay_map.setdefault(link, [])\n",
    "        path_delays.append(path_delay)\n",
    "    \n",
    "    def _get_valid_delay(self, link, delay):\n",
    "        valid_list = self.valid_delay_map.setdefault(link, [self.max_delay])\n",
    "        if delay == DataProcess.INVALID_ITEM:\n",
    "            if len(valid_list) < self.stat_size:\n",
    "                item_list = self.link_delay_map[link]\n",
    "                s_loc = -min(len(item_list), self.stat_size)\n",
    "                valid_delay = np.median(item_list[s_loc:])\n",
    "            else:\n",
    "                valid_delay = np.median(valid_list)\n",
    "        else:\n",
    "            if len(valid_list) >= self.stat_size:\n",
    "                valid_list.pop(0)\n",
    "            valid_list.append(delay)\n",
    "            if len(valid_list) < len(self.avg_weight):\n",
    "                valid_delay = sum(valid_list)/len(valid_list)\n",
    "            else:\n",
    "                s_loc = -len(self.avg_weight)\n",
    "                valid_delay = sum([self.avg_weight[i]*d \\\n",
    "                    for i, d in enumerate(valid_list[s_loc:])])\n",
    "        return valid_delay\n",
    "        \n",
    "    def _get_valid_loads(self, link, loads):\n",
    "        valid_list = self.valid_loads_map.setdefault(link, [0])\n",
    "        if loads == DataProcess.INVALID_ITEM:\n",
    "            valid_loads = 0\n",
    "        else:\n",
    "            if len(valid_list) >= self.stat_size:\n",
    "                valid_list.pop(0)\n",
    "            valid_list.append(loads)\n",
    "            if len(valid_list) < len(self.avg_weight):\n",
    "                valid_loads = sum(valid_list)/len(valid_list)\n",
    "            else:\n",
    "                s_loc = -len(self.avg_weight)\n",
    "                valid_loads = sum([self.avg_weight[i]*d \\\n",
    "                    for i, d in enumerate(valid_list[s_loc:])])\n",
    "        return valid_loads\n",
    "        \n",
    "    def _get_link_quality(self, line):\n",
    "        res_list = line.split()\n",
    "        link = ''.join(res_list[:3])\n",
    "        delay = float(res_list[-2])\n",
    "        loads = float(res_list[-1])\n",
    "        \n",
    "        # The key idea of this tricks locates at that, the delay beyond a so called 'max_delay' should\n",
    "        # make no sense to indicate the link quality, as well as the reliability of the links.\n",
    "        # Statistic of the median delay of the links of the target dpid, so as to obtain the valid delay\n",
    "        # which is used to indicated the reliability of the links.\n",
    "        \n",
    "        if delay > self.max_delay:\n",
    "            delay = self._get_valid_delay(link, \n",
    "                                         DataProcess.INVALID_ITEM)\n",
    "            loads = self._get_valid_loads(link,\n",
    "                                         DataProcess.INVALID_ITEM)\n",
    "        else:\n",
    "            delay = self._get_valid_delay(link, delay)\n",
    "            loads = self._get_valid_loads(link, loads)\n",
    "            \n",
    "        tq = 1 - np.tanh(delay/self.max_delay)\n",
    "        lq = 1 / (1 + np.exp(-(loads-self.max_bw*self.cong_rate)))\n",
    "        \n",
    "        # The degree of indicating link quality mainly depends on the delay quality, e.g., \n",
    "        # Link A: high loads, low delay\n",
    "        # Link B: low loads, low delay\n",
    "        # Link C: high loads, high delay\n",
    "        # Link D: low loads, high delay \n",
    "        # we hat A > B > C > D\n",
    "        # Eq. Q = (Qt + np.exp(Qt-max_Qt) * Ql) / 2, where max_Qt = 1-np.tanh(0) = 1\n",
    "        quality = tq * (1 + np.exp(tq - 1) * lq) / 2 \n",
    "        quality_list = self.quality_map.setdefault(link, [])\n",
    "        quality_list.append(quality)\n",
    "    \n",
    "    def _get_data_item(self, line):\n",
    "        res_list = line.split()\n",
    "        link = ''.join(res_list[:3])\n",
    "        dpid = link.split(':')[0]\n",
    "        if not dpid in self.target_dpids:\n",
    "            return \n",
    "        path_delay = float(res_list[-2])\n",
    "        cs_delay = float(res_list[-3])\n",
    "        sc_delay = float(res_list[-4])\n",
    "        delay = path_delay - (cs_delay + sc_delay)/2\n",
    "        if delay < self.min_delay:\n",
    "            delay = self.min_delay\n",
    "        if any([x in link for x in self.fake_eps]):\n",
    "            is_forged_link = True \n",
    "        else:\n",
    "            is_forged_link = False \n",
    "        data_item = [cs_delay, sc_delay, delay, is_forged_link]\n",
    "        self.dataset.append(data_item)\n",
    "    \n",
    "    def query_quality_map(self):\n",
    "        return self.quality_map \n",
    "    \n",
    "    def query_delay_map(self):\n",
    "        return self.link_delay_map\n",
    "    \n",
    "    def query_delay_map2(self):\n",
    "        return self.path_delay_map\n",
    "    \n",
    "    def query_dataset(self):\n",
    "        return np.array(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike other methods, Detect_OOBLFA_2017 is essentially static and \n",
    "# the best p_value threshold is 5% (the smaller in [5%, 10%, 15%, 20%], the better)\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "\n",
    "class Detect_OOBLFA_2017:\n",
    "    def __init__(self, delay_map, train_range, test_range, fake_eps):\n",
    "        self.delay_map = delay_map\n",
    "        self.train_range = train_range\n",
    "        self.test_range = test_range\n",
    "        self.target_dpids = self._get_target_dpids(fake_eps)\n",
    "        self.fake_links = self._get_fake_links(fake_eps)\n",
    "        self.p_value_thr = 0.05\n",
    "        self.simulations = 1000\n",
    "        self.vetting_period_range = range(2, 500)\n",
    "        self.train_set_size = 2500 # use the first benign link for test\n",
    "        self.test_set_size = 1000\n",
    "        # b for benign, a for adversary\n",
    "        self.train_sample_set, self.test_map = self._prepare()\n",
    "        random.seed(9527) # fix the seed for reproduction\n",
    "    \n",
    "    def _get_target_dpids(self, fake_eps):\n",
    "        target_dpids = set()\n",
    "        for ep in fake_eps:\n",
    "            dpid = ep[0]\n",
    "            target_dpids.add(dpid)\n",
    "        return target_dpids\n",
    "    \n",
    "    def _get_fake_links(self, fake_eps):\n",
    "        fake_links = []\n",
    "        for link in self.delay_map.keys():\n",
    "            for ep in fake_eps:\n",
    "                if ep in link:\n",
    "                    fake_links.append(link)\n",
    "                    break \n",
    "        return fake_links \n",
    "    \n",
    "    # Collect 2500 train samples\n",
    "    def _prepare(self):\n",
    "        test_map = {}\n",
    "        for i, (k, v) in enumerate(self.delay_map.items()):\n",
    "            if i == 0:\n",
    "                train_set = v[:self.train_set_size]\n",
    "                break\n",
    "        \n",
    "        for i, k in enumerate(self.delay_map.keys()):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            start_idx = self.test_range[0]\n",
    "            if len(self.test_range) < self.test_set_size:\n",
    "                end_idx = start_idx + len(self.test_range)\n",
    "            else:\n",
    "                end_idx = start_idx + self.test_set_size\n",
    "            test_map[k] = self.delay_map[k][start_idx:end_idx]        \n",
    "        return train_set[:self.train_set_size], test_map\n",
    "    \n",
    "    def fit(self):\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "\n",
    "        for _ in range(self.simulations):\n",
    "            for vp in self.vetting_period_range:\n",
    "                # start to test each link\n",
    "                for link, sample_set in self.test_map.items():\n",
    "                    dpid = link.split(':')[0]\n",
    "                    if dpid not in self.target_dpids:\n",
    "                        continue\n",
    "                    train_set = random.choices(self.train_sample_set, k=vp)\n",
    "                    test_set = random.choices(sample_set, k=vp)\n",
    "                    _, p_value = stats.ttest_ind(train_set, test_set)\n",
    "                    pred_flag = True if p_value < self.p_value_thr else False \n",
    "                    true_flag = True if link in self.fake_links else False\n",
    "                    y_pred.append(pred_flag)\n",
    "                    y_true.append(true_flag)\n",
    "        return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          name : Detect_OOBLFA_2017,\n",
      "          TPR: 0.733824297188755,\n",
      "          FPR: 0.3720411646586345,\n",
      "          Precision: 0.6635746594010398,\n",
      "          f1_score: 0.6969336935181044,\n",
      "          auc_score: 0.6808915662650601\n",
      "          \n",
      "\n",
      "          name : Detect_OOBLFA_2017,\n",
      "          TPR: 0.323745983935743,\n",
      "          FPR: 0.29716616465863455,\n",
      "          Precision: 0.5214038486259931,\n",
      "          f1_score: 0.3994614812610159,\n",
      "          auc_score: 0.5132899096385543\n",
      "          \n",
      "\n",
      "          name : Detect_OOBLFA_2017,\n",
      "          TPR: 0.3847906626506024,\n",
      "          FPR: 0.3096586345381526,\n",
      "          Precision: 0.5540946822299314,\n",
      "          f1_score: 0.45417784207412404,\n",
      "          auc_score: 0.5375660140562248\n",
      "          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3847906626506024,\n",
       " 0.3096586345381526,\n",
       " 0.5540946822299314,\n",
       " 0.45417784207412404,\n",
       " 0.5375660140562248)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log Detect_OOBLFA_2017  result\n",
    "start_range = range(0, 2500) # must > 2500\n",
    "test_range = range(2000, 3000)\n",
    "\n",
    "do2017 = Detect_OOBLFA_2017(delays[0], start_range, test_range, ['2:1', '4:1'])\n",
    "y_pred, y_true = do2017.fit()\n",
    "show_model_metrics('Detect_OOBLFA_2017', y_true, y_pred)\n",
    "\n",
    "do2017 = Detect_OOBLFA_2017(delays[1], start_range, test_range, ['2:1', '4:1'])\n",
    "y_pred, y_true = do2017.fit()\n",
    "show_model_metrics('Detect_OOBLFA_2017', y_true, y_pred)\n",
    "\n",
    "do2017 = Detect_OOBLFA_2017(delays[2], start_range, test_range, ['2:1', '4:1'])\n",
    "y_pred, y_true = do2017.fit()\n",
    "show_model_metrics('Detect_OOBLFA_2017', y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopoGuardPlus:\n",
    "    def __init__(self, delay_map, start_range, test_range, fake_eps):\n",
    "        self.delay_map = delay_map\n",
    "        self.start_range = start_range \n",
    "        self.test_range = test_range\n",
    "        self.target_dpids = self._get_target_dpids(fake_eps)\n",
    "        self.fake_links = self._get_fake_links(fake_eps)\n",
    "        self.link_delay_queue = self._prepare()\n",
    "    \n",
    "    def _get_target_dpids(self, fake_eps):\n",
    "        target_dpids = set()\n",
    "        for ep in fake_eps:\n",
    "            dpid = ep[0]\n",
    "            target_dpids.add(dpid)\n",
    "        return target_dpids\n",
    "    \n",
    "    def _get_fake_links(self, fake_eps):\n",
    "        fake_links = []\n",
    "        for link in self.delay_map.keys():\n",
    "            for ep in fake_eps:\n",
    "                if ep in link:\n",
    "                    fake_links.append(link)\n",
    "                    break \n",
    "        return fake_links \n",
    "    \n",
    "    def _prepare(self):\n",
    "        link_delay_queue = []\n",
    "        for i in self.start_range:\n",
    "            for link, delay_list in self.delay_map.items():\n",
    "                dpid = link.split(':')[0]\n",
    "                if dpid in self.target_dpids and \\\n",
    "                    link not in self.fake_links:\n",
    "                    link_delay_queue.append(delay_list[i])\n",
    "        return link_delay_queue\n",
    "    \n",
    "    def fit(self):\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for i in self.test_range:\n",
    "            Q1 = np.quantile(self.link_delay_queue, 0.25)\n",
    "            Q3 = np.quantile(self.link_delay_queue, 0.75)\n",
    "            thr = Q3 + 3 * (Q3 - Q1)\n",
    "            for link, delay_list in self.delay_map.items():\n",
    "                dpid = link.split(':')[0]\n",
    "                if dpid not in self.target_dpids:\n",
    "                    continue\n",
    "                curr_delay = delay_list[i]\n",
    "                self.link_delay_queue.append(curr_delay)\n",
    "                pred_flag = 1 if curr_delay > thr else False \n",
    "                true_flag = 1 if link in self.fake_links else False\n",
    "                y_pred.append(pred_flag) \n",
    "                y_true.append(true_flag)\n",
    "        return y_pred, y_true             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrustTopo:\n",
    "    def __init__(self, delay_map, start_range, test_range, fake_eps):\n",
    "        self.delay_map = delay_map\n",
    "        self.start_range = start_range \n",
    "        self.test_range = test_range\n",
    "        self.target_dpids = self._get_target_dpids(fake_eps)\n",
    "        self.fake_links = self._get_fake_links(fake_eps)\n",
    "        self.link_delay_queue = self._prepare()\n",
    "        self.C = 0.5\n",
    "\n",
    "    def _get_target_dpids(self, fake_eps):\n",
    "        target_dpids = set()\n",
    "        for ep in fake_eps:\n",
    "            dpid = ep[0]\n",
    "            target_dpids.add(dpid)\n",
    "        return target_dpids\n",
    "    \n",
    "    def _get_fake_links(self, fake_eps):\n",
    "        fake_links = []\n",
    "        for link in self.delay_map.keys():\n",
    "            for ep in fake_eps:\n",
    "                if ep in link:\n",
    "                    fake_links.append(link)\n",
    "                    break \n",
    "        return fake_links \n",
    "    \n",
    "    def _prepare(self):\n",
    "        link_delay_queue = []\n",
    "        for i in self.start_range:\n",
    "            for link, delay_list in self.delay_map.items():\n",
    "                dpid = link.split(':')[0]\n",
    "                if dpid in self.target_dpids and \\\n",
    "                    link not in self.fake_links:\n",
    "                    link_delay_queue.append(delay_list[i])\n",
    "        # sort\n",
    "        link_delay_queue.sort()\n",
    "        # strip the ends \n",
    "        link_delay_queue.pop(0)\n",
    "        link_delay_queue.pop(-1)\n",
    "        return link_delay_queue\n",
    "\n",
    "    def train(self, delay):\n",
    "        tmp_queue = np.array(self.link_delay_queue)\n",
    "        med = np.median(tmp_queue)\n",
    "        prop = np.sum(tmp_queue > med) / len(tmp_queue)\n",
    "        delta = max(delay-med, 0)\n",
    "        thr = med + prop * delta + self.C\n",
    "        return thr\n",
    "    \n",
    "    def fit(self):\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        thr = self.train(0)\n",
    "        for i in self.test_range:\n",
    "            for link, delay_list in self.delay_map.items():\n",
    "                dpid = link.split(':')[0]\n",
    "                if dpid not in self.target_dpids:\n",
    "                    continue\n",
    "                curr_delay = delay_list[i]\n",
    "                pred_flag = True if curr_delay > thr else False \n",
    "                true_flag = True if link in self.fake_links else False\n",
    "                y_pred.append(pred_flag) \n",
    "                y_true.append(true_flag)\n",
    "                # update \n",
    "                if not pred_flag:\n",
    "                    self.link_delay_queue.append(curr_delay)\n",
    "                    thr = self.train(curr_delay)\n",
    "                #print('thr: {}, current delay: {}'.format(thr, curr_delay))\n",
    "        return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTAD:\n",
    "    def __init__(self, delay_map, start_range, test_range, fake_eps):\n",
    "        self.delay_map = delay_map\n",
    "        self.start_range = start_range \n",
    "        self.test_range = test_range\n",
    "        self.target_dpids = self._get_target_dpids(fake_eps)\n",
    "        self.fake_links = self._get_fake_links(fake_eps)\n",
    "        self.link_delay_queue = self._prepare()\n",
    "    \n",
    "    def _get_target_dpids(self, fake_eps):\n",
    "        target_dpids = set()\n",
    "        for ep in fake_eps:\n",
    "            dpid = ep[0]\n",
    "            target_dpids.add(dpid)\n",
    "        return target_dpids\n",
    "    \n",
    "    def _get_fake_links(self, fake_eps):\n",
    "        fake_links = []\n",
    "        for link in self.delay_map.keys():\n",
    "            for ep in fake_eps:\n",
    "                if ep in link:\n",
    "                    fake_links.append(link)\n",
    "                    break \n",
    "        return fake_links \n",
    "    \n",
    "    def _prepare(self):\n",
    "        link_delay_queue = []\n",
    "        for i in self.start_range:\n",
    "            for link, delay_list in self.delay_map.items():\n",
    "                dpid = link.split(':')[0]\n",
    "                if dpid in self.target_dpids and \\\n",
    "                    link not in self.fake_links:\n",
    "                    link_delay_queue.append(delay_list[i])\n",
    "        return link_delay_queue\n",
    "    \n",
    "    def fit(self):\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for i in self.test_range:\n",
    "            Q1 = np.quantile(self.link_delay_queue, 0.25)\n",
    "            Q3 = np.quantile(self.link_delay_queue, 0.75)\n",
    "            thr = Q3 + 1.5 * (Q3 - Q1) # 1.5IQR + Q3\n",
    "            for link, delay_list in self.delay_map.items():\n",
    "                dpid = link.split(':')[0]\n",
    "                if dpid not in self.target_dpids:\n",
    "                    continue\n",
    "                curr_delay = delay_list[i]\n",
    "                self.link_delay_queue.append(curr_delay)\n",
    "                pred_flag = 1 if curr_delay > thr else False \n",
    "                true_flag = 1 if link in self.fake_links else False\n",
    "                y_pred.append(pred_flag) \n",
    "                y_true.append(true_flag)\n",
    "        return y_pred, y_true             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同于其它方法，LinkGuard本质上是静态的，所以它的阈值是不更新的。\n",
    "class LinkGuard:\n",
    "    def __init__(self, delay_map, train_range, test_range, fake_eps):\n",
    "        self.delay_map = delay_map\n",
    "        self.train_range = train_range\n",
    "        self.test_range = test_range\n",
    "        self.target_dpids = self._get_target_dpids(fake_eps)\n",
    "        self.fake_links = self._get_fake_links(fake_eps)\n",
    "    \n",
    "    def _get_target_dpids(self, fake_eps):\n",
    "        target_dpids = set()\n",
    "        for ep in fake_eps:\n",
    "            dpid = ep[0]\n",
    "            target_dpids.add(dpid)\n",
    "        return target_dpids\n",
    "    \n",
    "    def _get_fake_links(self, fake_eps):\n",
    "        fake_links = []\n",
    "        for link in self.delay_map.keys():\n",
    "            for ep in fake_eps:\n",
    "                if ep in link:\n",
    "                    fake_links.append(link)\n",
    "                    break \n",
    "        return fake_links \n",
    "    \n",
    "    def train(self):\n",
    "        link_delay_queue = []\n",
    "        for i in self.train_range:\n",
    "            for link, delay_list in self.delay_map.items():\n",
    "                dpid = link.split(':')[0]\n",
    "                if dpid in self.target_dpids and \\\n",
    "                    link not in self.fake_links:\n",
    "                    link_delay_queue.append(delay_list[i])\n",
    "        Q1 = np.quantile(link_delay_queue, 0.25)\n",
    "        Q3 = np.quantile(link_delay_queue, 0.75)\n",
    "        thr = Q3 + 3 * (Q3 - Q1)\n",
    "        return thr\n",
    "    \n",
    "    def fit(self):\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        thr = self.train()\n",
    "        for i in self.test_range:\n",
    "            for link, delay_list in self.delay_map.items():\n",
    "                dpid = link.split(':')[0]\n",
    "                if dpid not in self.target_dpids:\n",
    "                    continue \n",
    "                curr_delay = delay_list[i]\n",
    "                pred_flag = True if curr_delay > thr else False \n",
    "                true_flag = True if link in self.fake_links else False \n",
    "                y_pred.append(pred_flag)\n",
    "                y_true.append(true_flag)\n",
    "        return y_pred, y_true \n",
    "    # def fit(self):\n",
    "    #     y_pred = []\n",
    "    #     y_true = []\n",
    "    #     thr = self.train()\n",
    "    #     # we don't set it to 10 as the original paper, because the performance is much worse than TTL=1\n",
    "    #     TTL = 1 \n",
    "    #     measure_result = {}\n",
    "    #     pred_result = {}\n",
    "    #     for i in self.test_range:\n",
    "    #         for link, delay_list in self.delay_map.items():\n",
    "    #             dpid = link.split(':')[0]\n",
    "    #             if dpid not in self.target_dpids:\n",
    "    #                 continue\n",
    "    #             measure_result.setdefault(link, [])\n",
    "    #             pred_result.setdefault(link, [])\n",
    "    #             curr_delay = delay_list[i]\n",
    "    #             measure_result[link].append(curr_delay)\n",
    "    #             if len(measure_result[link]) % TTL == 0:\n",
    "    #                 measure_dealy = np.median(measure_result[link])\n",
    "    #                 measure_result[link].clear()\n",
    "    #                 pred_flag = True if measure_dealy > thr else False\n",
    "    #                 pred_result[link].extend([pred_flag] * TTL) \n",
    "    #             true_flag = True if link in self.fake_links else False\n",
    "    #             y_true.append(true_flag)\n",
    "    #     # In python 3.9, the keys are fix-ordered in dict.\n",
    "    #     batch_size = len(self.test_range)\n",
    "    #     for i in range(batch_size):\n",
    "    #         for v in pred_result.values():\n",
    "    #             y_pred.append(v[i])\n",
    "    #     assert(len(y_pred) == len(y_true)) \n",
    "    #     return y_pred, y_true      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_metrics(model_name, y_true, y_pred):   \n",
    "    cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    TN, FP, FN, TP = cnf_matrix.ravel()\n",
    "    \n",
    "    FP = FP.astype(float)\n",
    "    FN = FN.astype(float)\n",
    "    TP = TP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "    \n",
    "    TPR = TP/(TP+FN)\n",
    "    FPR = FP/(FP+TN)\n",
    "    \n",
    "    Pr = precision_score(y_true, y_pred)\n",
    "    F1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    # Error, the 2nd param of roc_auc_score is not y_pred\n",
    "    # but y_score, which is the probability of y_pred \n",
    "    AUC = roc_auc_score(y_true, y_pred)\n",
    "    print(f'''\n",
    "          name : {model_name},\n",
    "          TPR: {TPR},\n",
    "          FPR: {FPR},\n",
    "          Precision: {Pr},\n",
    "          f1_score: {F1},\n",
    "          auc_score: {AUC}\n",
    "          ''')\n",
    "    return TPR, FPR, Pr, F1, AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_model_predict(model, model_name, dataset):\n",
    "    dataset = np.array(dataset)\n",
    "    X, y = dataset[:,:-1], dataset[:,-1]\n",
    "    multi_step_model = ['lr', 'rf', 'svc', 'mlp']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.334, random_state=0)\n",
    "    clf = model.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    if model_name in multi_step_model:\n",
    "        y_pred[y_pred > 0.5] = 1\n",
    "        y_pred[y_pred <= 0.5] = 0\n",
    "    return y_pred, y_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_result(model, model_name, X, y, param_grid):\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='roc_auc')\n",
    "    grid_search.fit(X ,y)\n",
    "    print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_config = {\n",
    "    'fake_eps': ['2:1', '4:1'],\n",
    "    'min_delay': 0.5,\n",
    "    'max_delay': 5,\n",
    "    'max_bw': 100,\n",
    "    'cong_rate': 0.8,\n",
    "    'stat_size': 100,\n",
    "    'avg_weight': [0.1, 0.2, 0.3, 0.4],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic test\n",
    "num_switch = 5\n",
    "\n",
    "data_files = [\n",
    "    # r'../dataset/{}switches/pcap_link_0.5_no_load_no_attack.txt'.format(num_switch),\n",
    "    r'../dataset/{}switches/pcap_link_0.5_load_no_attack.txt'.format(num_switch), # changed for reviewer\n",
    "    r'../dataset/{}switches/pcap_link_0.5_no_load_attack.txt'.format(num_switch),\n",
    "    r'../dataset/{}switches/pcap_link_0.5_load_attack.txt'.format(num_switch),]\n",
    "\n",
    "data_size = 14*3000\n",
    "\n",
    "processors = [\n",
    "    DataProcess(data_file, data_size, ds_config) for data_file in data_files]\n",
    "\n",
    "for p in processors:\n",
    "    p.preprocess()\n",
    "\n",
    "delays = [p.query_delay_map() for p in processors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          name : TopoGuardPlus,\n",
      "          TPR: 0.05125,\n",
      "          FPR: 0.00525,\n",
      "          Precision: 0.9070796460176991,\n",
      "          f1_score: 0.09701845716990061,\n",
      "          auc_score: 0.523\n",
      "          \n",
      "\n",
      "          name : TopoGuardPlus,\n",
      "          TPR: 0.06625,\n",
      "          FPR: 0.0385,\n",
      "          Precision: 0.6324582338902148,\n",
      "          f1_score: 0.11993663724824621,\n",
      "          auc_score: 0.513875\n",
      "          \n",
      "\n",
      "          name : TopoGuardPlus,\n",
      "          TPR: 0.09275,\n",
      "          FPR: 0.06075,\n",
      "          Precision: 0.6042345276872965,\n",
      "          f1_score: 0.16081491114000868,\n",
      "          auc_score: 0.5160000000000001\n",
      "          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09275, 0.06075, 0.6042345276872965, 0.16081491114000868, 0.5160000000000001)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log TopoGuard+ result\n",
    "start_range = range(0, 2000)\n",
    "test_range = range(2000, 3000)\n",
    "\n",
    "topoguard_plus = TopoGuardPlus(delays[0], start_range, test_range, ['2:1', '4:1'])\n",
    "y_pred, y_true = topoguard_plus.fit()\n",
    "show_model_metrics('TopoGuardPlus', y_true, y_pred)\n",
    "\n",
    "topoguard_plus = TopoGuardPlus(delays[1], start_range, test_range, ['2:1', '4:1'])\n",
    "y_pred, y_true = topoguard_plus.fit()\n",
    "show_model_metrics('TopoGuardPlus', y_true, y_pred)\n",
    "\n",
    "topoguard_plus = TopoGuardPlus(delays[2], start_range, test_range, ['2:1', '4:1'])\n",
    "y_pred, y_true = topoguard_plus.fit()\n",
    "show_model_metrics('TopoGuardPlus', y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          name : CTAD,\n",
      "          TPR: 0.256,\n",
      "          FPR: 0.023,\n",
      "          Precision: 0.9175627240143369,\n",
      "          f1_score: 0.400312744331509,\n",
      "          auc_score: 0.6164999999999999\n",
      "          \n",
      "\n",
      "          name : CTAD,\n",
      "          TPR: 0.19475,\n",
      "          FPR: 0.061,\n",
      "          Precision: 0.761485826001955,\n",
      "          f1_score: 0.3101732032649811,\n",
      "          auc_score: 0.566875\n",
      "          \n",
      "\n",
      "          name : CTAD,\n",
      "          TPR: 0.16925,\n",
      "          FPR: 0.0755,\n",
      "          Precision: 0.6915219611848825,\n",
      "          f1_score: 0.2719421570596506,\n",
      "          auc_score: 0.5468749999999999\n",
      "          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.16925, 0.0755, 0.6915219611848825, 0.2719421570596506, 0.5468749999999999)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log CTAD result\n",
    "start_range = range(0, 2000)\n",
    "test_range = range(2000, 3000)\n",
    "\n",
    "ctad = CTAD(delays[0], start_range, test_range, ['2:1', '4:1'])\n",
    "y_pred, y_true = ctad.fit()\n",
    "show_model_metrics('CTAD', y_true, y_pred)\n",
    "\n",
    "ctad = CTAD(delays[1], start_range, test_range, ['2:1', '4:1'])\n",
    "y_pred, y_true = ctad.fit()\n",
    "show_model_metrics('CTAD', y_true, y_pred)\n",
    "\n",
    "ctad = CTAD(delays[2], start_range, test_range, ['2:1', '4:1'])\n",
    "y_pred, y_true = ctad.fit()\n",
    "show_model_metrics('CTAD', y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          name : TrustTopo,\n",
      "          TPR: 0.5825,\n",
      "          FPR: 0.1465,\n",
      "          Precision: 0.799039780521262,\n",
      "          f1_score: 0.6737998843262002,\n",
      "          auc_score: 0.718\n",
      "          \n",
      "\n",
      "          name : TrustTopo,\n",
      "          TPR: 0.52525,\n",
      "          FPR: 0.177,\n",
      "          Precision: 0.7479530081879673,\n",
      "          f1_score: 0.617124394184168,\n",
      "          auc_score: 0.6741249999999999\n",
      "          \n",
      "\n",
      "          name : TrustTopo,\n",
      "          TPR: 0.53825,\n",
      "          FPR: 0.21425,\n",
      "          Precision: 0.7152823920265781,\n",
      "          f1_score: 0.614265335235378,\n",
      "          auc_score: 0.6619999999999999\n",
      "          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.53825, 0.21425, 0.7152823920265781, 0.614265335235378, 0.6619999999999999)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_range = range(0, 2000)\n",
    "test_range = range(2000, 3000)\n",
    "\n",
    "trust_topo = TrustTopo(delays[0], start_range, test_range, ['2:1', '4:1'])\n",
    "y_pred, y_true = trust_topo.fit()\n",
    "show_model_metrics('TrustTopo', y_true, y_pred)\n",
    "\n",
    "trust_topo = TrustTopo(delays[1], start_range, test_range, ['2:1', '4:1'])\n",
    "y_pred, y_true = trust_topo.fit()\n",
    "show_model_metrics('TrustTopo', y_true, y_pred)\n",
    "\n",
    "\n",
    "trust_topo = TrustTopo(delays[2], start_range, test_range, ['2:1', '4:1'])\n",
    "y_pred, y_true = trust_topo.fit()\n",
    "show_model_metrics('TrustTopo', y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          name : LinkGuard,\n",
      "          TPR: 0.08075,\n",
      "          FPR: 0.008,\n",
      "          Precision: 0.9098591549295775,\n",
      "          f1_score: 0.14833524684270954,\n",
      "          auc_score: 0.536375\n",
      "          \n",
      "\n",
      "          name : LinkGuard,\n",
      "          TPR: 0.07625,\n",
      "          FPR: 0.0435,\n",
      "          Precision: 0.6367432150313153,\n",
      "          f1_score: 0.13619111408796605,\n",
      "          auc_score: 0.516375\n",
      "          \n",
      "\n",
      "          name : LinkGuard,\n",
      "          TPR: 0.1075,\n",
      "          FPR: 0.06625,\n",
      "          Precision: 0.6187050359712231,\n",
      "          f1_score: 0.18317358892438762,\n",
      "          auc_score: 0.5206249999999999\n",
      "          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1075, 0.06625, 0.6187050359712231, 0.18317358892438762, 0.5206249999999999)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_range = range(0, 2000)\n",
    "test_range = range(2000, 3000)\n",
    "\n",
    "link_guard = LinkGuard(delays[0], train_range, test_range, ['2:1', '4:1'])\n",
    "y_pred, y_true = link_guard.fit()\n",
    "show_model_metrics('LinkGuard', y_true, y_pred)\n",
    "\n",
    "link_guard = LinkGuard(delays[1], train_range, test_range, ['2:1', '4:1'])\n",
    "y_pred, y_true = link_guard.fit()\n",
    "show_model_metrics('LinkGuard', y_true, y_pred)\n",
    "\n",
    "\n",
    "link_guard = LinkGuard(delays[2], train_range, test_range, ['2:1', '4:1'])\n",
    "y_pred, y_true = link_guard.fit()\n",
    "show_model_metrics('LinkGuard', y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [processor.query_dataset() for processor in processors]\n",
    "\n",
    "lr = LinearRegression()\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "svc = SVC(random_state=0)\n",
    "knn = KNeighborsClassifier()\n",
    "mlp = MLPClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          name : lr,\n",
      "          TPR: 0.4751614505712866,\n",
      "          FPR: 0.06514657980456026,\n",
      "          Precision: 0.8803497468936954,\n",
      "          f1_score: 0.6171963219874174,\n",
      "          auc_score: 0.7050074353833632\n",
      "          \n",
      "\n",
      "          name : lr,\n",
      "          TPR: 0.31718827620466966,\n",
      "          FPR: 0.13355048859934854,\n",
      "          Precision: 0.7055248618784531,\n",
      "          f1_score: 0.4376285126799178,\n",
      "          auc_score: 0.5918188938026605\n",
      "          \n",
      "\n",
      "          name : lr,\n",
      "          TPR: 0.20968944099378883,\n",
      "          FPR: 0.12675350701402804,\n",
      "          Precision: 0.6251851851851852,\n",
      "          f1_score: 0.31404651162790703,\n",
      "          auc_score: 0.5414679669898805\n",
      "          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.20968944099378883,\n",
       " 0.12675350701402804,\n",
       " 0.6251851851851852,\n",
       " 0.31404651162790703,\n",
       " 0.5414679669898805)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear regression\n",
    "\n",
    "y_pred, y_true = query_model_predict(lr, 'lr', datasets[0])\n",
    "show_model_metrics('lr', y_true, y_pred)\n",
    "\n",
    "y_pred, y_true = query_model_predict(lr, 'lr', datasets[1])\n",
    "show_model_metrics('lr', y_true, y_pred)\n",
    "\n",
    "y_pred, y_true = query_model_predict(lr, 'lr', datasets[2])\n",
    "show_model_metrics('lr', y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          name : dt,\n",
      "          TPR: 0.6333830104321908,\n",
      "          FPR: 0.34452518165873214,\n",
      "          Precision: 0.6496815286624203,\n",
      "          f1_score: 0.6414287511004905,\n",
      "          auc_score: 0.6444289143867293\n",
      "          \n",
      "\n",
      "          name : dt,\n",
      "          TPR: 0.6458022851465475,\n",
      "          FPR: 0.31921824104234525,\n",
      "          Precision: 0.6711409395973155,\n",
      "          f1_score: 0.6582278481012659,\n",
      "          auc_score: 0.6632920220521011\n",
      "          \n",
      "\n",
      "          name : dt,\n",
      "          TPR: 0.5845962732919254,\n",
      "          FPR: 0.36723446893787576,\n",
      "          Precision: 0.6161298769311339,\n",
      "          f1_score: 0.5999490056093829,\n",
      "          auc_score: 0.6086809021770249\n",
      "          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5845962732919254,\n",
       " 0.36723446893787576,\n",
       " 0.6161298769311339,\n",
       " 0.5999490056093829,\n",
       " 0.6086809021770249)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, y_true = query_model_predict(dt, 'dt', datasets[0])\n",
    "show_model_metrics('dt', y_true, y_pred)\n",
    "\n",
    "y_pred, y_true = query_model_predict(dt, 'dt', datasets[1])\n",
    "show_model_metrics('dt', y_true, y_pred)\n",
    "\n",
    "y_pred, y_true = query_model_predict(dt, 'dt', datasets[2])\n",
    "show_model_metrics('dt', y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          name : rf,\n",
      "          TPR: 0.559612518628912,\n",
      "          FPR: 0.10949636682535706,\n",
      "          Precision: 0.8375464684014869,\n",
      "          f1_score: 0.670935080405003,\n",
      "          auc_score: 0.7250580759017775\n",
      "          \n",
      "\n",
      "          name : rf,\n",
      "          TPR: 0.6423248882265276,\n",
      "          FPR: 0.1839138060636432,\n",
      "          Precision: 0.7789156626506024,\n",
      "          f1_score: 0.7040566294582086,\n",
      "          auc_score: 0.7292055410814422\n",
      "          \n",
      "\n",
      "          name : rf,\n",
      "          TPR: 0.6404968944099378,\n",
      "          FPR: 0.24223446893787576,\n",
      "          Precision: 0.7272214386459802,\n",
      "          f1_score: 0.68110964332893,\n",
      "          auc_score: 0.6991312127360312\n",
      "          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6404968944099378,\n",
       " 0.24223446893787576,\n",
       " 0.7272214386459802,\n",
       " 0.68110964332893,\n",
       " 0.6991312127360312)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "# {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 16} for dataset 0\n",
    "# {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 20} for dataset 1\n",
    "# {'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 20} for dataset 2\n",
    "# dataset = datasets[2]\n",
    "# param_grid = {\n",
    "#     'n_estimators': [i for i in range(1, 21)],\n",
    "#     'max_depth': [i for i in range(1, 11)]\n",
    "# }\n",
    "\n",
    "# X, y = dataset[:,:-1], dataset[:,-1]\n",
    "# search_result(rf, 'rf', X, y, param_grid)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, max_depth=10, n_estimators=16)\n",
    "y_pred, y_true = query_model_predict(rf, 'rf', datasets[0])\n",
    "show_model_metrics('rf', y_true, y_pred)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, max_depth=10, n_estimators=20)\n",
    "y_pred, y_true = query_model_predict(rf, 'rf', datasets[1])\n",
    "show_model_metrics('rf', y_true, y_pred)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, max_depth=10, n_estimators=20)\n",
    "y_pred, y_true = query_model_predict(rf, 'rf', datasets[2])\n",
    "show_model_metrics('rf', y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          name : svc,\n",
      "          TPR: 0.568802781917536,\n",
      "          FPR: 0.11200200451014783,\n",
      "          Precision: 0.8366824990865912,\n",
      "          f1_score: 0.6772142540292769,\n",
      "          auc_score: 0.7284003887036941\n",
      "          \n",
      "\n",
      "          name : svc,\n",
      "          TPR: 0.7036761053154496,\n",
      "          FPR: 0.2598346279128038,\n",
      "          Precision: 0.7320413436692507,\n",
      "          f1_score: 0.71757852077001,\n",
      "          auc_score: 0.7219207387013228\n",
      "          \n",
      "\n",
      "          name : svc,\n",
      "          TPR: 0.6479503105590062,\n",
      "          FPR: 0.2655310621242485,\n",
      "          Precision: 0.7110141766630316,\n",
      "          f1_score: 0.6780189782919538,\n",
      "          auc_score: 0.6912096242173789\n",
      "          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6479503105590062,\n",
       " 0.2655310621242485,\n",
       " 0.7110141766630316,\n",
       " 0.6780189782919538,\n",
       " 0.6912096242173789)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC\n",
    "# {'C': 5000} for all dataset\n",
    "# dataset = datasets[2]\n",
    "# print(len(dataset))\n",
    "# param_grid = {\n",
    "#     'C': [i for i in range(1000, 6000, 1000)],\n",
    "# }\n",
    "# X, y = dataset[:,:-1], dataset[:,-1]\n",
    "# search_result(svc, 'svc', X, y, param_grid)\n",
    "\n",
    "svc = SVC(random_state=0, C=5000)\n",
    "y_pred, y_true = query_model_predict(svc, 'svc', datasets[0])\n",
    "show_model_metrics('svc', y_true, y_pred)\n",
    "\n",
    "svc = SVC(random_state=0, C=5000)\n",
    "y_pred, y_true = query_model_predict(svc, 'svc', datasets[1])\n",
    "show_model_metrics('svc', y_true, y_pred)\n",
    "\n",
    "svc = SVC(random_state=0, C=5000)\n",
    "y_pred, y_true = query_model_predict(svc, 'svc', datasets[2])\n",
    "show_model_metrics('svc', y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          name : knn,\n",
      "          TPR: 0.5958768007948336,\n",
      "          FPR: 0.15058882485592584,\n",
      "          Precision: 0.7996666666666666,\n",
      "          f1_score: 0.6828921150014233,\n",
      "          auc_score: 0.722643987969454\n",
      "          \n",
      "\n",
      "          name : knn,\n",
      "          TPR: 0.6443119721808246,\n",
      "          FPR: 0.19543973941368079,\n",
      "          Precision: 0.7688203912270303,\n",
      "          f1_score: 0.701081081081081,\n",
      "          auc_score: 0.7244361163835719\n",
      "          \n",
      "\n",
      "          name : knn,\n",
      "          TPR: 0.6091925465838509,\n",
      "          FPR: 0.2342184368737475,\n",
      "          Precision: 0.7239444936521996,\n",
      "          f1_score: 0.6616297895304911,\n",
      "          auc_score: 0.6874870548550518\n",
      "          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6091925465838509,\n",
       " 0.2342184368737475,\n",
       " 0.7239444936521996,\n",
       " 0.6616297895304911,\n",
       " 0.6874870548550518)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knn\n",
    "# {'n_neighbors': 20} for all dataset\n",
    "\n",
    "#dataset = datasets[2]\n",
    "# param_grid = {\n",
    "#     'n_neighbors': [i for i in range(1, 21)],\n",
    "# }\n",
    "\n",
    "# X, y = dataset[:,:-1], dataset[:,-1]\n",
    "# search_result(knn, 'knn', X, y, param_grid)\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=20)\n",
    "y_pred, y_true = query_model_predict(knn1, 'knn', datasets[0])\n",
    "show_model_metrics('knn', y_true, y_pred)\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=20)\n",
    "y_pred, y_true = query_model_predict(knn2, 'knn', datasets[1])\n",
    "show_model_metrics('knn', y_true, y_pred)\n",
    "\n",
    "knn3 = KNeighborsClassifier(n_neighbors=20)\n",
    "y_pred, y_true = query_model_predict(knn3, 'knn', datasets[2])\n",
    "show_model_metrics('knn', y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          name : mlp,\n",
      "          TPR: 0.6222056631892697,\n",
      "          FPR: 0.17639689300927086,\n",
      "          Precision: 0.7806170146463073,\n",
      "          f1_score: 0.6924671734623359,\n",
      "          auc_score: 0.7229043850899994\n",
      "          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          name : mlp,\n",
      "          TPR: 0.6661698956780924,\n",
      "          FPR: 0.19919819594086696,\n",
      "          Precision: 0.7713546160483176,\n",
      "          f1_score: 0.7149140343862455,\n",
      "          auc_score: 0.7334858498686128\n",
      "          \n",
      "\n",
      "          name : mlp,\n",
      "          TPR: 0.6792546583850931,\n",
      "          FPR: 0.3076152304609218,\n",
      "          Precision: 0.6900555275113579,\n",
      "          f1_score: 0.6846124953048703,\n",
      "          auc_score: 0.6858197139620856\n",
      "          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6792546583850931,\n",
       " 0.3076152304609218,\n",
       " 0.6900555275113579,\n",
       " 0.6846124953048703,\n",
       " 0.6858197139620856)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = datasets[0]\n",
    "\n",
    "# # dataset \n",
    "# # {'activation': 'relu', 'hidden_layer_data_sizes': 8} for dataset 0\n",
    "# # {'activation': 'tanh', 'hidden_layer_data_sizes': 10} for dataset 1 \n",
    "# # {'activation': 'tanh', 'hidden_layer_data_sizes': 10} for dataset 2\n",
    "# param_grid = {\n",
    "#     'hidden_layer_sizes': [i for i in range(1, 11)],\n",
    "#     'activation': ['identity', 'logistic', 'tanh', 'relu']\n",
    "# }\n",
    "\n",
    "# X, y = dataset[:,:-1], dataset[:,-1]\n",
    "# search_result(mlp, 'mlp', X, y, param_grid)\n",
    "\n",
    "mlp = MLPClassifier(activation='tanh', hidden_layer_sizes=10)\n",
    "y_pred, y_true = query_model_predict(mlp, 'mlp', datasets[0])\n",
    "show_model_metrics('mlp', y_true, y_pred)\n",
    "\n",
    "mlp = MLPClassifier(activation='tanh', hidden_layer_sizes=10)\n",
    "y_pred, y_true = query_model_predict(mlp, 'mlp', datasets[1])\n",
    "show_model_metrics('mlp', y_true, y_pred)\n",
    "\n",
    "mlp = MLPClassifier(activation='tanh', hidden_layer_sizes=10)\n",
    "y_pred, y_true = query_model_predict(mlp, 'mlp', datasets[2])\n",
    "show_model_metrics('mlp', y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_switch = 100\n",
    "# period_size = 2 * num_switch + 4 \n",
    "period_size = 2 * 4 # number of fake switches * number of links\n",
    "data_file = r'../dataset/{}switches/pcap_link_0.5_load_attack.txt'.format(num_switch)\n",
    "data_size = 10000000\n",
    "processor = DataProcess(data_file, data_size, ds_config)\n",
    "processor.preprocess()\n",
    "\n",
    "delay_map = processor.query_delay_map()\n",
    "dataset = processor.query_dataset()\n",
    "start_range = range(0, 2000)\n",
    "test_range = range(2000, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log topoguard+ result\n",
    "for s in range(0, 5100, 100):\n",
    "    start_range = range(s, s+2000)\n",
    "    test_range = range(s+2000, s+3000)\n",
    "\n",
    "    topoguard_plus = TopoGuardPlus(delay_map, start_range, test_range, ['2:1', '4:1'])\n",
    "    y_pred, y_true = topoguard_plus.fit()\n",
    "    TPR, FPR, Pr, F1, AUC = show_model_metrics('topoguard+', y_true, y_pred)\n",
    "    with open('topoguard_log/topoguard_log_{}.txt'.format(num_switch), 'a+') as fp:\n",
    "        fp.write('TPR:{},FPR:{},Pr:{},F1:{},AUC:{}\\n'.format(\n",
    "            TPR, FPR, Pr, F1, AUC\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.1465,\n",
      "          FPR: 0.15725,\n",
      "          Precision: 0.4823045267489712,\n",
      "          f1_score: 0.22473633748801536,\n",
      "          auc_score: 0.49462500000000004\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.14875,\n",
      "          FPR: 0.15825,\n",
      "          Precision: 0.48452768729641693,\n",
      "          f1_score: 0.2276205049732211,\n",
      "          auc_score: 0.49524999999999997\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.14625,\n",
      "          FPR: 0.15675,\n",
      "          Precision: 0.48267326732673266,\n",
      "          f1_score: 0.22448196469685341,\n",
      "          auc_score: 0.49475\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.14125,\n",
      "          FPR: 0.15125,\n",
      "          Precision: 0.4829059829059829,\n",
      "          f1_score: 0.21856866537717604,\n",
      "          auc_score: 0.49499999999999994\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.13825,\n",
      "          FPR: 0.15,\n",
      "          Precision: 0.47961838681699914,\n",
      "          f1_score: 0.21463225305647196,\n",
      "          auc_score: 0.494125\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.14225,\n",
      "          FPR: 0.155,\n",
      "          Precision: 0.4785534062237174,\n",
      "          f1_score: 0.21931007901329735,\n",
      "          auc_score: 0.493625\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.1465,\n",
      "          FPR: 0.155,\n",
      "          Precision: 0.4859038142620232,\n",
      "          f1_score: 0.22512485593545908,\n",
      "          auc_score: 0.49575\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.14525,\n",
      "          FPR: 0.1535,\n",
      "          Precision: 0.48619246861924686,\n",
      "          f1_score: 0.22367661212704523,\n",
      "          auc_score: 0.49587499999999995\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.1445,\n",
      "          FPR: 0.15575,\n",
      "          Precision: 0.48126561199000834,\n",
      "          f1_score: 0.22226494904825994,\n",
      "          auc_score: 0.494375\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.147,\n",
      "          FPR: 0.161,\n",
      "          Precision: 0.4772727272727273,\n",
      "          f1_score: 0.22477064220183485,\n",
      "          auc_score: 0.493\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.147,\n",
      "          FPR: 0.16075,\n",
      "          Precision: 0.4776604386677498,\n",
      "          f1_score: 0.22481361116421336,\n",
      "          auc_score: 0.49312500000000004\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.1435,\n",
      "          FPR: 0.16025,\n",
      "          Precision: 0.47242798353909465,\n",
      "          f1_score: 0.22013422818791947,\n",
      "          auc_score: 0.491625\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.1385,\n",
      "          FPR: 0.154,\n",
      "          Precision: 0.4735042735042735,\n",
      "          f1_score: 0.2143133462282399,\n",
      "          auc_score: 0.49225\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.13575,\n",
      "          FPR: 0.153,\n",
      "          Precision: 0.4701298701298701,\n",
      "          f1_score: 0.21066925315227936,\n",
      "          auc_score: 0.491375\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.1365,\n",
      "          FPR: 0.15375,\n",
      "          Precision: 0.4702842377260982,\n",
      "          f1_score: 0.2115869017632242,\n",
      "          auc_score: 0.49137499999999995\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.13525,\n",
      "          FPR: 0.15175,\n",
      "          Precision: 0.4712543554006969,\n",
      "          f1_score: 0.21017871017871018,\n",
      "          auc_score: 0.49174999999999996\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.138,\n",
      "          FPR: 0.1555,\n",
      "          Precision: 0.47018739352640543,\n",
      "          f1_score: 0.2133745651333591,\n",
      "          auc_score: 0.49124999999999996\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.14,\n",
      "          FPR: 0.1605,\n",
      "          Precision: 0.46589018302828616,\n",
      "          f1_score: 0.21530180699730878,\n",
      "          auc_score: 0.4897500000000001\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.14225,\n",
      "          FPR: 0.16025,\n",
      "          Precision: 0.47024793388429753,\n",
      "          f1_score: 0.218426103646833,\n",
      "          auc_score: 0.491\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.14875,\n",
      "          FPR: 0.167,\n",
      "          Precision: 0.47110055423594616,\n",
      "          f1_score: 0.2261067832034961,\n",
      "          auc_score: 0.49087499999999995\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.1525,\n",
      "          FPR: 0.172,\n",
      "          Precision: 0.4699537750385208,\n",
      "          f1_score: 0.2302755756889392,\n",
      "          auc_score: 0.4902500000000001\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.159,\n",
      "          FPR: 0.175,\n",
      "          Precision: 0.47604790419161674,\n",
      "          f1_score: 0.2383808095952024,\n",
      "          auc_score: 0.492\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.1615,\n",
      "          FPR: 0.178,\n",
      "          Precision: 0.47569955817378495,\n",
      "          f1_score: 0.24113475177304963,\n",
      "          auc_score: 0.49175\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.16725,\n",
      "          FPR: 0.1805,\n",
      "          Precision: 0.4809489575844716,\n",
      "          f1_score: 0.2481914301613801,\n",
      "          auc_score: 0.49337500000000006\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.169,\n",
      "          FPR: 0.18275,\n",
      "          Precision: 0.48045486851457003,\n",
      "          f1_score: 0.25004623636027373,\n",
      "          auc_score: 0.49312500000000004\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.16725,\n",
      "          FPR: 0.17925,\n",
      "          Precision: 0.48268398268398266,\n",
      "          f1_score: 0.24842183438544374,\n",
      "          auc_score: 0.49400000000000005\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.1735,\n",
      "          FPR: 0.18175,\n",
      "          Precision: 0.4883884588318086,\n",
      "          f1_score: 0.2560413207895222,\n",
      "          auc_score: 0.495875\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.17575,\n",
      "          FPR: 0.18475,\n",
      "          Precision: 0.48751733703190014,\n",
      "          f1_score: 0.2583608967291437,\n",
      "          auc_score: 0.49550000000000005\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.1755,\n",
      "          FPR: 0.1825,\n",
      "          Precision: 0.49022346368715086,\n",
      "          f1_score: 0.25846833578792344,\n",
      "          auc_score: 0.49649999999999994\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.17725,\n",
      "          FPR: 0.1855,\n",
      "          Precision: 0.48862853204686424,\n",
      "          f1_score: 0.26013575490735646,\n",
      "          auc_score: 0.49587499999999995\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.16725,\n",
      "          FPR: 0.17425,\n",
      "          Precision: 0.48975109809663253,\n",
      "          f1_score: 0.24934774506149832,\n",
      "          auc_score: 0.49650000000000005\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.16375,\n",
      "          FPR: 0.17375,\n",
      "          Precision: 0.48518518518518516,\n",
      "          f1_score: 0.24485981308411214,\n",
      "          auc_score: 0.49500000000000005\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.15925,\n",
      "          FPR: 0.1705,\n",
      "          Precision: 0.4829416224412434,\n",
      "          f1_score: 0.23951870652378265,\n",
      "          auc_score: 0.49437500000000006\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.1555,\n",
      "          FPR: 0.1705,\n",
      "          Precision: 0.47699386503067487,\n",
      "          f1_score: 0.23453996983408748,\n",
      "          auc_score: 0.4925\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.149,\n",
      "          FPR: 0.15975,\n",
      "          Precision: 0.4825910931174089,\n",
      "          f1_score: 0.22769818529130847,\n",
      "          auc_score: 0.494625\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.15225,\n",
      "          FPR: 0.163,\n",
      "          Precision: 0.4829500396510706,\n",
      "          f1_score: 0.2315149211176582,\n",
      "          auc_score: 0.494625\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.14875,\n",
      "          FPR: 0.1625,\n",
      "          Precision: 0.4779116465863454,\n",
      "          f1_score: 0.22688274547187798,\n",
      "          auc_score: 0.493125\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.14575,\n",
      "          FPR: 0.15775,\n",
      "          Precision: 0.4802306425041186,\n",
      "          f1_score: 0.22362869198312238,\n",
      "          auc_score: 0.494\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.142,\n",
      "          FPR: 0.157,\n",
      "          Precision: 0.47491638795986624,\n",
      "          f1_score: 0.2186297151655119,\n",
      "          auc_score: 0.49249999999999994\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.13325,\n",
      "          FPR: 0.14775,\n",
      "          Precision: 0.47419928825622776,\n",
      "          f1_score: 0.2080405932864949,\n",
      "          auc_score: 0.49275\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.13775,\n",
      "          FPR: 0.15325,\n",
      "          Precision: 0.4733676975945017,\n",
      "          f1_score: 0.2134004647560031,\n",
      "          auc_score: 0.49225\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.14275,\n",
      "          FPR: 0.1565,\n",
      "          Precision: 0.47702589807852963,\n",
      "          f1_score: 0.21974215893784874,\n",
      "          auc_score: 0.493125\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.14075,\n",
      "          FPR: 0.15325,\n",
      "          Precision: 0.47874149659863946,\n",
      "          f1_score: 0.2175425038639876,\n",
      "          auc_score: 0.49374999999999997\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.13275,\n",
      "          FPR: 0.14425,\n",
      "          Precision: 0.47924187725631767,\n",
      "          f1_score: 0.20790916209866878,\n",
      "          auc_score: 0.49425\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.13125,\n",
      "          FPR: 0.1455,\n",
      "          Precision: 0.4742547425474255,\n",
      "          f1_score: 0.20560015664773842,\n",
      "          auc_score: 0.49287500000000006\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.134,\n",
      "          FPR: 0.149,\n",
      "          Precision: 0.4734982332155477,\n",
      "          f1_score: 0.20888542478565864,\n",
      "          auc_score: 0.49249999999999994\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.135,\n",
      "          FPR: 0.1505,\n",
      "          Precision: 0.47285464098073554,\n",
      "          f1_score: 0.21003500583430576,\n",
      "          auc_score: 0.49225\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.139,\n",
      "          FPR: 0.15725,\n",
      "          Precision: 0.46919831223628694,\n",
      "          f1_score: 0.2144648023143684,\n",
      "          auc_score: 0.490875\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.139,\n",
      "          FPR: 0.16,\n",
      "          Precision: 0.46488294314381273,\n",
      "          f1_score: 0.21401077752117015,\n",
      "          auc_score: 0.4895\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.13575,\n",
      "          FPR: 0.155,\n",
      "          Precision: 0.46689595872742906,\n",
      "          f1_score: 0.21034282393957,\n",
      "          auc_score: 0.490375\n",
      "          \n",
      "\n",
      "          name : ctad,\n",
      "          TPR: 0.13325,\n",
      "          FPR: 0.14925,\n",
      "          Precision: 0.47168141592920354,\n",
      "          f1_score: 0.2077972709551657,\n",
      "          auc_score: 0.49200000000000005\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "# log ctad result\n",
    "for s in range(0, 5100, 100):\n",
    "    start_range = range(s, s+2000)\n",
    "    test_range = range(s+2000, s+3000)\n",
    "\n",
    "    ctad = CTAD(delay_map, start_range, test_range, ['2:1', '4:1'])\n",
    "    y_pred, y_true = ctad.fit()\n",
    "    TPR, FPR, Pr, F1, AUC = show_model_metrics('ctad', y_true, y_pred)\n",
    "    with open('ctad_log/ctad_log_{}.txt'.format(num_switch), 'a+') as fp:\n",
    "        fp.write('TPR:{},FPR:{},Pr:{},F1:{},AUC:{}\\n'.format(\n",
    "            TPR, FPR, Pr, F1, AUC\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log trustopo result\n",
    "for s in range(0, 5100, 100):\n",
    "    start_range = range(s, s+2000)\n",
    "    test_range = range(s+2000, s+3000)\n",
    "\n",
    "    trust_topo = TrustTopo(delay_map, start_range, test_range, ['2:1', '4:1'])\n",
    "    y_pred, y_true = trust_topo.fit()\n",
    "\n",
    "    TPR, FPR, Pr, F1, AUC = show_model_metrics('trust_topo', y_true, y_pred)\n",
    "    with open('trusttopo_log/trusttopo_log_{}.txt'.format(num_switch), 'a+') as fp:\n",
    "        fp.write('TPR:{},FPR:{},Pr:{},F1:{},AUC:{}\\n'.format(\n",
    "            TPR, FPR, Pr, F1, AUC\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log linkguard result\n",
    "for s in range(0, 5100, 100):\n",
    "    train_range = range(s, s+2000)\n",
    "    test_range = range(s+2000, s+3000)\n",
    "\n",
    "    link_guard = LinkGuard(delay_map, train_range, test_range, ['2:1', '4:1'])\n",
    "    y_pred, y_true = link_guard.fit()\n",
    "    \n",
    "    TPR, FPR, Pr, F1, AUC = show_model_metrics('link_guard', y_true, y_pred)\n",
    "    with open('linkguard_log/linkguard_log_{}.txt'.format(num_switch), 'a+') as fp:\n",
    "        fp.write('TPR:{},FPR:{},Pr:{},F1:{},AUC:{}\\n'.format(\n",
    "            TPR, FPR, Pr, F1, AUC\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log rlv result\n",
    "\n",
    "for s in range(0, 5100, 100):\n",
    "    rf = RandomForestClassifier(random_state=0, max_depth=10, n_estimators=20)\n",
    "    y_pred, y_true = query_model_predict(rf, 'rf', dataset[s*period_size:(s+3000)*period_size])\n",
    "    TPR, FPR, Pr, F1, AUC = show_model_metrics('rf', y_true, y_pred)\n",
    "    with open('rf_log/rf_log_{}.txt'.format(num_switch), 'a+') as fp:\n",
    "        fp.write('TPR:{},FPR:{},Pr:{},F1:{},AUC:{}\\n'.format(\n",
    "            TPR, FPR, Pr, F1, AUC\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log rlv result\n",
    "for s in range(0, 5100, 100):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=10, activation='tanh')\n",
    "    y_pred, y_true = query_model_predict(mlp, 'mlp', dataset[s*period_size:(s+3000)*period_size])\n",
    "    TPR, FPR, Pr, F1, AUC = show_model_metrics('mlp', y_true, y_pred)\n",
    "    with open('mlp_log/mlp_log_{}.txt'.format(num_switch), 'a+') as fp:\n",
    "        fp.write('TPR:{},FPR:{},Pr:{},F1:{},AUC:{}\\n'.format(\n",
    "            TPR, FPR, Pr, F1, AUC\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
